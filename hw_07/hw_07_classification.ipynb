{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно каким-то образом загрузить данные. И попробовать нарисовать на них bouding box-ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import natsort\n",
    "\n",
    "bboxes = []\n",
    "# load json\n",
    "with open('team_classification_data\\\\bboxes.json') as bboxes_json:\n",
    "    bboxes = json.load(bboxes_json)\n",
    "\n",
    "# load images \n",
    "data_dir = 'team_classification_data\\\\frames\\\\'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.jpeg']\n",
    "sorted_filenames = natsort.natsorted(filenames)\n",
    "\n",
    "image_tensors = [torchvision.io.read_image(data_dir + name) for name in sorted_filenames]\n",
    "batch = torch.stack(image_tensors)\n",
    "\n",
    "for bb, fn, tens in zip(bboxes.items(), sorted_filenames, image_tensors):\n",
    "    print(f'{bb[0]} - {fn}')\n",
    "\n",
    "    team_list = []\n",
    "    bboxes_list = []\n",
    "    for player_id, bbox in bb[1].items():\n",
    "        height = tens.shape[1]\n",
    "        width = tens.shape[2]\n",
    "\n",
    "        x = bbox['box'][0] * width\n",
    "        y = bbox['box'][1] * height\n",
    "        w = bbox['box'][2] * width\n",
    "        h = bbox['box'][3] * height\n",
    "\n",
    "        bboxes_list.append([x, y, w, h])\n",
    "        team_list.append(int(player_id))\n",
    "\n",
    "    bboxes_tensor = torch.tensor(bboxes_list)\n",
    "    print(bboxes_tensor.shape)\n",
    "    print(bboxes_tensor)\n",
    "    bboxes_tensor = torchvision.ops.box_convert(bboxes_tensor[1], 'xywh', 'xyxy')\n",
    "\n",
    "    if bb[0] > '2000': \n",
    "        img = utils.draw_bounding_boxes(tens, bboxes_tensor[1], width=2, colors='green')\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        img.show()\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Loading team_classification_data\\frames\\1310.jpeg...\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class TeamClassificationDataset(Dataset):\n",
    "    def __init__(self, img_folder_path, bboxes_file_path, transform = None):\n",
    "        super().__init__()\n",
    "        self.img_folder_path = img_folder_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.bboxes = {}\n",
    "        with open(bboxes_file_path) as bboxes_json:\n",
    "            self.bboxes = json.load(bboxes_json)\n",
    "            self.bboxes = list(self.bboxes.items())\n",
    "            # print ('type(self.bboxes) = ', type(self.bboxes))\n",
    "            # print(self.bboxes[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bboxes)\n",
    "\n",
    "    def load_image(self, imgage_path):\n",
    "        image = Image.open(imgage_path).convert('RGB')\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = f'{self.img_folder_path}\\\\{self.bboxes[index][0]}.jpeg'\n",
    "        print(f'Loading {img_path}...')\n",
    "        img = self.load_image(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        bbox = self.bboxes[index]\n",
    "        return img, bbox\n",
    "\n",
    "\n",
    "transform = v2.Compose([\n",
    "                v2.PILToTensor(), # uint8 [0, 255]\n",
    "                v2.ToDtype(dtype=torch.float32, scale=True), # float32, [0, 1]\n",
    "                v2.Normalize((0.5,), (0.5,)), # (img - mean) / std [-1, 1]\n",
    "           ])\n",
    "\n",
    "train_dataset = TeamClassificationDataset('team_classification_data\\\\frames',\n",
    "                                          'team_classification_data\\\\bboxes.json',\n",
    "                                           transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "\n",
    "print(len(train_dataset))\n",
    "\n",
    "# for img, bbox in train_dataloader:\n",
    "#     print(bbox)\n",
    "\n",
    "\n",
    "img, bbox = next(iter(train_dataloader))\n",
    "print(type(bbox[1]))\n",
    "\n",
    "\n",
    "# img = torch.squeeze(img, 0)\n",
    "# print(img.shape, type(img))\n",
    "\n",
    "# plt.imshow(  img.permute(1, 2, 0),  )\n",
    "\n",
    "# img = transforms.ToPILImage()(img)\n",
    "# img.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
