{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно каким-то образом загрузить данные. И попробовать нарисовать на них bouding box-ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import functional\n",
    "\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import natsort\n",
    "\n",
    "bboxes = []\n",
    "# load json\n",
    "with open('team_classification_data\\\\bboxes.json') as bboxes_json:\n",
    "    bboxes = json.load(bboxes_json)\n",
    "\n",
    "# load images \n",
    "data_dir = 'team_classification_data\\\\frames\\\\'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.jpeg']\n",
    "sorted_filenames = natsort.natsorted(filenames)\n",
    "\n",
    "image_tensors = [torchvision.io.read_image(data_dir + name) for name in sorted_filenames]\n",
    "batch = torch.stack(image_tensors)\n",
    "\n",
    "for bb, fn, tens in zip(bboxes.items(), sorted_filenames, image_tensors):\n",
    "    print(f'{bb[0]} - {fn}')\n",
    "\n",
    "    team_list = []\n",
    "    bboxes_list = []\n",
    "    for player_id, bbox in bb[1].items():\n",
    "        height = tens.shape[1]\n",
    "        width = tens.shape[2]\n",
    "\n",
    "        x = bbox['box'][0] * width\n",
    "        y = bbox['box'][1] * height\n",
    "        w = bbox['box'][2] * width\n",
    "        h = bbox['box'][3] * height\n",
    "\n",
    "        bboxes_list.append([x, y, w, h])\n",
    "        team_list.append(int(player_id))\n",
    "\n",
    "    bboxes_tensor = torch.tensor(bboxes_list)\n",
    "    print(bboxes_tensor.shape)\n",
    "    print(bboxes_tensor)\n",
    "    bboxes_tensor = torchvision.ops.box_convert(bboxes_tensor[1], 'xywh', 'xyxy')\n",
    "\n",
    "    if bb[0] > '2000': \n",
    "        img = utils.draw_bounding_boxes(tens, bboxes_tensor[1], width=2, colors='green')\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        img.show()\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamClassificationDataset(Dataset):\n",
    "    def __init__(self, img_folder_path, bboxes_file_path, transform = None, debug_img_show = False):\n",
    "        super().__init__()\n",
    "        self.img_folder_path = img_folder_path\n",
    "        self.transform = transform\n",
    "        self.debug_img_show = debug_img_show\n",
    "\n",
    "        self.bboxes = {}\n",
    "        with open(bboxes_file_path) as bboxes_json:\n",
    "            self.bboxes = json.load(bboxes_json)\n",
    "            self.bboxes = list(self.bboxes.items())\n",
    "            # print ('type(self.bboxes) = ', type(self.bboxes))\n",
    "            # print(self.bboxes[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bboxes)\n",
    "\n",
    "    def load_image(self, imgage_path):\n",
    "        image = Image.open(imgage_path).convert('RGB')\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = f'{self.img_folder_path}\\\\{self.bboxes[index][0]}.jpeg'\n",
    "        #print(f'Loading {img_path}...')\n",
    "        img = self.load_image(img_path)\n",
    "        height = img.height\n",
    "        width = img.width\n",
    "\n",
    "        if self.transform:\n",
    "            transformed_img = self.transform(img)\n",
    "\n",
    "        # process bboxes\n",
    "        team_list = []\n",
    "        bboxes_list = []\n",
    "        colors_list = []\n",
    "        for id, player in self.bboxes[index][1].items():\n",
    "            box = player['box']\n",
    "            team = player['team']\n",
    "\n",
    "            x = box[0] * width\n",
    "            y = box[1] * height\n",
    "            w = box[2] * width\n",
    "            h = box[3] * height\n",
    "\n",
    "            bboxes_list.append([x, y, w, h])\n",
    "            team_list.append(int(team))\n",
    "            if int(team):\n",
    "                colors_list.append('green')\n",
    "            else:\n",
    "                colors_list.append('red')\n",
    "\n",
    "        bboxes_tensor = torch.tensor(bboxes_list)\n",
    "        bboxes_tensor = torchvision.ops.box_convert(bboxes_tensor, 'xywh', 'xyxy')\n",
    "\n",
    "        if self.debug_img_show:\n",
    "            debug_img = functional.pil_to_tensor(img)\n",
    "            debug_img = utils.draw_bounding_boxes(debug_img, bboxes_tensor, width=2, colors=colors_list)\n",
    "            debug_img = transforms.ToPILImage()(debug_img)\n",
    "            debug_img.show()\n",
    "\n",
    "        return {'image': transformed_img, \n",
    "                'bboxes_tensor': bboxes_tensor,\n",
    "                'teams_list': team_list}\n",
    "\n",
    "transform = v2.Compose([\n",
    "                v2.PILToTensor(), # uint8 [0, 255]\n",
    "                v2.ToDtype(dtype=torch.float32, scale=True), # float32, [0, 1]\n",
    "                v2.Normalize((0.5,), (0.5,)), # (img - mean) / std [-1, 1]\n",
    "           ])\n",
    "\n",
    "train_dataset = TeamClassificationDataset('team_classification_data\\\\frames',\n",
    "                                          'team_classification_data\\\\bboxes.json',\n",
    "                                           transform,\n",
    "                                           debug_img_show=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "\n",
    "i = 0\n",
    "for data in train_dataloader:\n",
    "    i = i + 1\n",
    "    if (i > 2):\n",
    "        break\n",
    "\n",
    "    # img = data['image']\n",
    "    # # bbox = data['bbox']\n",
    "    # # print(img.shape, bbox[1])\n",
    "    # height = img.shape[2]\n",
    "    # width = img.shape[3]\n",
    "\n",
    "    # for team_id, box in bbox[1].items():\n",
    "    #     bbox_list.append(normalize_bbox(height, width, box))\n",
    "\n",
    "    # bboxes_tensor = torch.tensor(bbox_list)\n",
    "    # bboxes_tensor = torchvision.ops.box_convert(bboxes_tensor[1], 'xywh', 'xyxy')\n",
    "\n",
    "    # img = utils.draw_bounding_boxes(img, bboxes_tensor[1], width=2, colors='green')\n",
    "    # if bbox[0][0] > '1':\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img, bbox = next(iter(train_dataloader))\n",
    "# print(type(bbox))\n",
    "\n",
    "\n",
    "# img = torch.squeeze(img, 0)\n",
    "# print(img.shape, type(img))\n",
    "\n",
    "# plt.imshow(  img.permute(1, 2, 0),  )\n",
    "\n",
    "# img = transforms.ToPILImage()(img)\n",
    "# img.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
