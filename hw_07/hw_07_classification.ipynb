{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно каким-то образом загрузить данные. И попробовать нарисовать на них bouding box-ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 720, 1280]) 100 <class 'dict'>\n",
      "1310  - 1310.jpeg\n",
      "1577  - 1577.jpeg\n",
      "2306  - 2306.jpeg\n",
      "2825  - 2825.jpeg\n",
      "3155  - 3155.jpeg\n",
      "5756  - 5756.jpeg\n",
      "5820  - 5820.jpeg\n",
      "6123  - 6123.jpeg\n",
      "6130  - 6130.jpeg\n",
      "6180  - 6180.jpeg\n",
      "7486  - 7486.jpeg\n",
      "14063  - 14063.jpeg\n",
      "16117  - 16117.jpeg\n",
      "19500  - 19500.jpeg\n",
      "21728  - 21728.jpeg\n",
      "21775  - 21775.jpeg\n",
      "22617  - 22617.jpeg\n",
      "22647  - 22647.jpeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m bboxes_tensor \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mbox_convert(bboxes_tensor, \u001b[39m'\u001b[39m\u001b[39mxywh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mxyxy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m img \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdraw_bounding_boxes(tens, bboxes_tensor, width\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, colors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39;49mToPILImage()(img)\n\u001b[0;32m     40\u001b[0m img\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:234\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    226\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_pil_image(pic, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\functional.py:323\u001b[0m, in \u001b[0;36mto_pil_image\u001b[1;34m(pic, mode)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput type \u001b[39m\u001b[39m{\u001b[39;00mnpimg\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 323\u001b[0m \u001b[39mreturn\u001b[39;00m Image\u001b[39m.\u001b[39;49mfromarray(npimg, mode\u001b[39m=\u001b[39;49mmode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3154\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3151\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3152\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[1;32m-> 3154\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3069\u001b[0m, in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   3066\u001b[0m         im\u001b[39m.\u001b[39mreadonly \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   3067\u001b[0m         \u001b[39mreturn\u001b[39;00m im\n\u001b[1;32m-> 3069\u001b[0m \u001b[39mreturn\u001b[39;00m frombytes(mode, size, data, decoder_name, args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3012\u001b[0m, in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   3009\u001b[0m     \u001b[39mif\u001b[39;00m decoder_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m args \u001b[39m==\u001b[39m ():\n\u001b[0;32m   3010\u001b[0m         args \u001b[39m=\u001b[39m mode\n\u001b[1;32m-> 3012\u001b[0m     im\u001b[39m.\u001b[39;49mfrombytes(data, decoder_name, args)\n\u001b[0;32m   3013\u001b[0m \u001b[39mreturn\u001b[39;00m im\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:826\u001b[0m, in \u001b[0;36mImage.frombytes\u001b[1;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m    824\u001b[0m d \u001b[39m=\u001b[39m _getdecoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, decoder_name, args)\n\u001b[0;32m    825\u001b[0m d\u001b[39m.\u001b[39msetimage(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim)\n\u001b[1;32m--> 826\u001b[0m s \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39;49mdecode(data)\n\u001b[0;32m    828\u001b[0m \u001b[39mif\u001b[39;00m s[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    829\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnot enough image data\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import natsort\n",
    "\n",
    "bboxes = []\n",
    "# load json\n",
    "with open('team_classification_data\\\\bboxes.json') as bboxes_json:\n",
    "    bboxes = json.load(bboxes_json)\n",
    "\n",
    "# load images \n",
    "data_dir = 'team_classification_data\\\\frames\\\\'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.jpeg']\n",
    "sorted_filenames = natsort.natsorted(filenames)\n",
    "\n",
    "image_tensors = [torchvision.io.read_image(data_dir + name) for name in sorted_filenames]\n",
    "batch = torch.stack(image_tensors)\n",
    "\n",
    "for bb, fn, tens in zip(bboxes.items(), sorted_filenames, image_tensors):\n",
    "    print(f'{bb[0]} - {fn}')\n",
    "\n",
    "    bboxes_list = []\n",
    "    for player_id, bbox in bb[1].items():\n",
    "        height = tens.shape[1]\n",
    "        width = tens.shape[2]\n",
    "\n",
    "        x = bbox['box'][0] * width\n",
    "        y = bbox['box'][1] * height\n",
    "        w = bbox['box'][2] * width\n",
    "        h = bbox['box'][3] * height\n",
    "\n",
    "        bboxes_list.append([x, y, w, h])\n",
    "\n",
    "    bboxes_tensor = torch.tensor(bboxes_list)\n",
    "    bboxes_tensor = torchvision.ops.box_convert(bboxes_tensor, 'xywh', 'xyxy')\n",
    "\n",
    "    img = utils.draw_bounding_boxes(tens, bboxes_tensor, width=2, colors='green')\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
