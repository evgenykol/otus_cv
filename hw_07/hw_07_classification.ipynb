{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import functional\n",
    "\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import natsort\n",
    "\n",
    "bboxes = []\n",
    "# load json\n",
    "with open('team_classification_data\\\\bboxes.json') as bboxes_json:\n",
    "    bboxes = json.load(bboxes_json)\n",
    "\n",
    "# load images \n",
    "data_dir = 'team_classification_data\\\\frames\\\\'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.jpeg']\n",
    "sorted_filenames = natsort.natsorted(filenames)\n",
    "\n",
    "image_tensors = [torchvision.io.read_image(data_dir + name) for name in sorted_filenames]\n",
    "batch = torch.stack(image_tensors)\n",
    "\n",
    "for bb, fn, tens in zip(bboxes.items(), sorted_filenames, image_tensors):\n",
    "    print(f'{bb[0]} - {fn}')\n",
    "\n",
    "    team_list = []\n",
    "    bboxes_list = []\n",
    "    for player_id, bbox in bb[1].items():\n",
    "        height = tens.shape[1]\n",
    "        width = tens.shape[2]\n",
    "\n",
    "        x = bbox['box'][0] * width\n",
    "        y = bbox['box'][1] * height\n",
    "        w = bbox['box'][2] * width\n",
    "        h = bbox['box'][3] * height\n",
    "\n",
    "        bboxes_list.append([x, y, w, h])\n",
    "        team_list.append(int(player_id))\n",
    "\n",
    "    bboxes_tensor = torch.tensor(bboxes_list)\n",
    "    print(bboxes_tensor.shape)\n",
    "    print(bboxes_tensor)\n",
    "    bboxes_tensor = torchvision.ops.box_convert(bboxes_tensor[1], 'xywh', 'xyxy')\n",
    "\n",
    "    if bb[0] > '2000': \n",
    "        img = utils.draw_bounding_boxes(tens, bboxes_tensor[1], width=2, colors='green')\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        img.show()\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamClassificationDataset(Dataset):\n",
    "    def __init__(self, img_folder_path, bboxes_file_path, transform = None, debug_img_show = False, debug_teams_train = False):\n",
    "        super(TeamClassificationDataset, self).__init__()\n",
    "        self.img_folder_path = img_folder_path\n",
    "        self.transform = transform\n",
    "        self.debug_img_show = debug_img_show\n",
    "        self.debug_teams_train = debug_teams_train\n",
    "\n",
    "        self.bboxes = {}\n",
    "        with open(bboxes_file_path) as bboxes_json:\n",
    "            self.bboxes = json.load(bboxes_json)\n",
    "            self.bboxes = list(self.bboxes.items())\n",
    "            # print ('type(self.bboxes) = ', type(self.bboxes))\n",
    "            # print(self.bboxes[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bboxes)\n",
    "\n",
    "    def load_image(self, imgage_path):\n",
    "        image = Image.open(imgage_path).convert('RGB')\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = f'{self.img_folder_path}\\\\{self.bboxes[index][0]}.jpeg'\n",
    "        #print(f'Loading {img_path}...')\n",
    "        img = self.load_image(img_path)\n",
    "        height = img.height\n",
    "        width = img.width\n",
    "\n",
    "        orig_img = img\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # process bboxes\n",
    "        team_list = []\n",
    "        lable_list = []\n",
    "        bboxes_list = []\n",
    "        colors_list = []\n",
    "        for id, player in self.bboxes[index][1].items():\n",
    "            box = player['box']\n",
    "            x = box[0] * width\n",
    "            y = box[1] * height\n",
    "            w = box[2] * width\n",
    "            h = box[3] * height\n",
    "            bboxes_list.append([x, y, w, h])\n",
    "\n",
    "            if self.debug_teams_train is True:\n",
    "                lable_list.append(id)\n",
    "\n",
    "                team = player['team']\n",
    "                team_list.append(int(team))\n",
    "                if int(team):\n",
    "                    colors_list.append('green')\n",
    "                else:\n",
    "                    colors_list.append('red')\n",
    "            else:\n",
    "                colors_list.append('blue')\n",
    "\n",
    "        bboxes_tensor = torch.tensor(bboxes_list)\n",
    "        bboxes_tensor_xyxy = torchvision.ops.box_convert(bboxes_tensor, 'xywh', 'xyxy')\n",
    "\n",
    "        if self.debug_img_show:\n",
    "            debug_img = functional.pil_to_tensor(orig_img)\n",
    "            debug_img = utils.draw_bounding_boxes(debug_img, \n",
    "                                                  bboxes_tensor_xyxy,\n",
    "                                                  width=2,\n",
    "                                                  colors=colors_list,\n",
    "                                                  labels=lable_list,\n",
    "                                                  font='verdana.ttf',\n",
    "                                                  font_size=20)\n",
    "            debug_img = transforms.ToPILImage()(debug_img)\n",
    "            debug_img.show()\n",
    "\n",
    "        return {'image': img, \n",
    "                'bboxes_tensor': bboxes_tensor,\n",
    "                'teams_list': team_list}\n",
    "\n",
    "transform = v2.Compose([\n",
    "                v2.PILToTensor(), # uint8 [0, 255]\n",
    "                v2.ToDtype(dtype=torch.float32, scale=True)# , # float32, [0, 1]\n",
    "                #v2.Normalize((0.5,), (0.5,)), # (img - mean) / std [-1, 1]\n",
    "           ])\n",
    "\n",
    "train_dataset = TeamClassificationDataset('team_classification_data\\\\frames',\n",
    "                                          'team_classification_data\\\\bboxes.json',\n",
    "                                           transform,\n",
    "                                           debug_img_show = False,\n",
    "                                           debug_teams_train = True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 720, 1280])\n",
      "torch.Size([3, 720, 1280])\n",
      "tensor(0.5117) tensor(0.4237) tensor(0.3785)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import crop, center_crop\n",
    "import numpy as np\n",
    "\n",
    "i = 0\n",
    "for data in train_dataloader:\n",
    "    i = i + 1\n",
    "    if (i > 2):\n",
    "        break\n",
    "\n",
    "    image = data['image']\n",
    "    bboxes = data['bboxes_tensor']\n",
    "\n",
    "    print(image.shape)\n",
    "    image = image.squeeze(0)\n",
    "    print(image.shape)\n",
    "    r, g, b = torch.mean(image, dim=[1, 2])\n",
    "    print(r, g, b)\n",
    "\n",
    "    for bb in bboxes[0]:\n",
    "        cropped = crop(image,\n",
    "                    left   = int(bb[0]),\n",
    "                    top    = int(bb[1]),\n",
    "                    width  = int(bb[2]),\n",
    "                    height = int(bb[3]))\n",
    "\n",
    "        cropped_im = transforms.ToPILImage()(cropped)\n",
    "        cropped_im.show()\n",
    "\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
