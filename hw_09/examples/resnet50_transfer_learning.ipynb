{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"171px"},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"oldHeight":325,"position":{"height":"347px","left":"536px","right":"20px","top":"545px","width":"350px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"varInspector_section_display":"block","window_display":false},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":109319,"sourceType":"datasetVersion","datasetId":56851}],"dockerImageVersionId":11105,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"For the general context, see  also:\n\n* A deepsense.ai blog post [Keras vs. PyTorch - Alien vs. Predator recognition with transfer learning](https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning) in which we compare and contrast Keras and PyTorch approaches.\n* Repo with code: [github.com/deepsense-ai/Keras-PyTorch-AvP-transfer-learning](https://github.com/deepsense-ai/Keras-PyTorch-AvP-transfer-learning).\n* Free event: [upcoming webinar (10 Oct 2018)](https://www.crowdcast.io/e/KerasVersusPyTorch/register), in which we walk trough the code (and you will be able to ask questions).\n\n### 1. Import dependencies","metadata":{"_uuid":"12d6a8f1134d0f16eb7e479dd8cdcb104ba7c653"}},{"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"_uuid":"e7397945384193360b50e41b8052a3292d1db75f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim","metadata":{"_uuid":"eb72fac76d6d250a6f63644340e443941a0ec802","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.__version__  # should be 0.4.1","metadata":{"_uuid":"7554266c3a0deabe52ae18973ca6b78a468f9d3f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\ntorchvision.__version__  # should be 0.2.1","metadata":{"_uuid":"871565acaaacbc7493fd933f34cab7c376174ecd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kaggle Kernel-dependent\ninput_path = \"../input/alien_vs_predator_thumbnails/data/\"","metadata":{"_uuid":"2f247ad045631f12116206e89fa30124c780f60a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Create PyTorch data generators","metadata":{"_uuid":"6090f5938db4e9685fc563b3ad6bd5adbd8f0bb7"}},{"cell_type":"code","source":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ]),\n    'validation':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize\n    ]),\n}\n\nimage_datasets = {\n    'train': \n    datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n    'validation': \n    datasets.ImageFolder(input_path + 'validation', data_transforms['validation'])\n}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=0),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=32,\n                                shuffle=False,\n                                num_workers=0)  # for Kaggle\n}","metadata":{"_uuid":"124e10a366db88235fc7a5716e791811cd202193","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Create the network","metadata":{"_uuid":"8e7d47a80fc9ae7e12ecde786ecd8df2ff4fc11e"}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"_uuid":"578892606f97f55335ee9954add8f71ff9a935c8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50(pretrained=True).to(device)\n    \nfor param in model.parameters():\n    param.requires_grad = False   \n    \nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)","metadata":{"_uuid":"776b85eaacbb1b53c5bb1e03abfb45d12b639db4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters())","metadata":{"_uuid":"01e7701173952cefb75cb0028179ca65f71feb30","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Train the model","metadata":{"_uuid":"11748461db9eac06eecf1fa9fd30f07eebf16025"}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=3):\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n\n            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc))\n    return model","metadata":{"_uuid":"9362fa736de086d3610a096c761c29a7117033fd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is some error (even though the same version work on my own computer):\n\n> RuntimeError: DataLoader worker (pid 56) is killed by signal: Bus error. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n> RuntimeError: DataLoader worker (pid 59) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n \nSee [this issue](https://github.com/pytorch/pytorch/issues/5301) and [that thread](https://discuss.pytorch.org/t/dataloader-randomly-crashes-after-few-epochs/20433/2). Setting `num_workers=0` in `DataLoader` solved it.","metadata":{"_uuid":"e3d926cb6f1406d70e5cbdcca1ce199e660a9c80"}},{"cell_type":"code","source":"model_trained = train_model(model, criterion, optimizer, num_epochs=3)","metadata":{"_uuid":"476b5d6e0a91a2fefd2a1803437674148f526182","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Save and load the model","metadata":{"_uuid":"c0606791b4a53b63fd624bc2670c8e0f3dd7a5af"}},{"cell_type":"code","source":"!mkdir models\n!mkdir models/pytorch","metadata":{"_uuid":"509031485a430b6dd82d5257d998eaacaea56808","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_trained.state_dict(), 'models/pytorch/weights.h5')","metadata":{"_uuid":"a423f25ece8d2f2baf4f1c3b8f4adc4118f750a5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50(pretrained=False).to(device)\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)\nmodel.load_state_dict(torch.load('models/pytorch/weights.h5'))","metadata":{"_uuid":"141db7f7ac8f64bf9d59ac770e60d77af938a799","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Make predictions on sample test images","metadata":{"_uuid":"e9e3f868d5d63b611db4c330ed91e4c724b62fa5"}},{"cell_type":"code","source":"validation_img_paths = [\"validation/alien/11.jpg\",\n                        \"validation/alien/22.jpg\",\n                        \"validation/predator/33.jpg\"]\nimg_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]","metadata":{"_uuid":"0f066f71893e37a99fee4960e05802dde822931e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_batch = torch.stack([data_transforms['validation'](img).to(device)\n                                for img in img_list])","metadata":{"_uuid":"5f7a7ebace882d1964835fad2dfaa237658788ef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_logits_tensor = model(validation_batch)\npred_logits_tensor","metadata":{"_uuid":"0adf2365151ece899007672d110a1e81e3a81e39","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\npred_probs","metadata":{"_uuid":"8a090957e80889d66a31f4817c3d5cbc7a9f8554","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\nfor i, img in enumerate(img_list):\n    ax = axs[i]\n    ax.axis('off')\n    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n                                                            100*pred_probs[i,1]))\n    ax.imshow(img)","metadata":{"_uuid":"f7068e5065cc37985e4b6ed7cdb32916cfccf04c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"ad8b90e800bb77317b3b58987d6461f1f91f5d41"},"execution_count":null,"outputs":[]}]}