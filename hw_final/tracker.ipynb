{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трекер для кастомной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-366-gf7322921 Python-3.9.19 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 182 layers, 7254609 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "models.common.AutoShape"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# model = YOLO(self.model_path) \n",
    "# model.fuse()\n",
    "\n",
    "\n",
    "\n",
    "model_name='best.pt'\n",
    "model = torch.hub.load(\"D:/projects/otus/otus_cv/hw_final/yolov5\", 'custom',\n",
    "                        source='local', path = \"D:/projects/otus/otus_cv/hw_final/yolov5/best.pt\", force_reload=True)\n",
    "\n",
    "type(model)\n",
    "#model.fuse()\n",
    "\n",
    "#model = torch.hub.load('D:/projects\\otus\\otus_cv\\hw_final\\weights','custom', path='best.pt',force_reload=True,source='local', pretrained = False)\n",
    "#model = torch.hub.load('.', 'custom', 'yolov5s.pt', source='local')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time  \n",
    "from ultralytics import YOLO\n",
    "\n",
    "from sort import Sort\n",
    "\n",
    "class ObjectDetection:\n",
    "\n",
    "    def __init__(self, capture_dev, model_path, weights_name, height=1280, width=720):\n",
    "        self.capture_dev = capture_dev\n",
    "        self.model_path = model_path\n",
    "        self.weights_name = weights_name\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Using Device: \", self.device)\n",
    "        \n",
    "        self.model = self.load_model()\n",
    "        # self.CLASS_NAMES_DICT = self.model.model.names\n",
    "\n",
    "    def load_model(self):\n",
    "        #model = YOLO(self.model_path) \n",
    "        model = torch.hub.load(self.model_path, 'custom', source='local', path = self.weights_name, force_reload=True)\n",
    "\n",
    "        #model.fuse()\n",
    "        return model\n",
    "\n",
    "    def predict(self, frame):\n",
    "        #results = self.model(frame, verbose=False)\n",
    "        results = self.model(frame)\n",
    "        print(results)\n",
    "        return results\n",
    "\n",
    "\n",
    "# image 1/1: 360x640 2 tractors\n",
    "# Speed: 2.2ms pre-process, 100.0ms inference, 1.0ms NMS per image at shape (1, 3, 384, 640)\n",
    "#          xmin        ymin        xmax       ymax  confidence  class     name\n",
    "# 0  319.510437  143.295914  370.080200  181.98262    0.655240      3  tractor\n",
    "# 1  226.162857  152.792435  286.686249  188.32872    0.529719      3  tractor\n",
    "    def get_results(self, results, img):\n",
    "        detections_list = []\n",
    "\n",
    "        data_frame = results.pandas().xyxy[0]\n",
    "        print('data_frame:')\n",
    "        print(data_frame)\n",
    "\n",
    "        # Get indexes of all of the rows\n",
    "        indexes = data_frame.index\n",
    "        for index in indexes:\n",
    "            # Find the coordinate of top left corner of bounding box\n",
    "            x1 = int(data_frame['xmin'][index])\n",
    "            y1 = int(data_frame['ymin'][index])\n",
    "            # Find the coordinate of right bottom corner of bounding box\n",
    "            x2 = int(data_frame['xmax'][index])\n",
    "            y2 = int(data_frame['ymax'][index ])\n",
    "\n",
    "            # Find label name\n",
    "            label = data_frame['name'][index ]\n",
    "            # Find confidance score of the model\n",
    "            conf = data_frame['confidence'][index]\n",
    "            text = label + ' ' + str(conf.round(decimals= 2))\n",
    "\n",
    "            merged_detection = [x1, y1, x2, y2, conf]\n",
    "            #[bbox[0][0], bbox[0][1], bbox[0][2], bbox[0][3], confidence[0]]\n",
    "            detections_list.append(merged_detection)\n",
    "\n",
    "        return np.array(detections_list)\n",
    "\n",
    "    def draw_bounding_boxes_with_id(self, img, bboxes, ids):\n",
    "        for bbox, id_ in zip(bboxes, ids):\n",
    "            cv2.rectangle(img,(int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])),(0,0,255),2)\n",
    "            cv2.putText(img, \"ID: \" + str(id_), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        return img\n",
    "\n",
    "    def __call__(self):\n",
    "        cap = cv2.VideoCapture(self.capture_dev)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.height)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.width)\n",
    "\n",
    "        # SORT\n",
    "        sort = Sort(max_age=100, min_hits=8, iou_threshold=0.50)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            start_time = time()\n",
    "            ret, frame = cap.read()\n",
    "            assert ret\n",
    "\n",
    "            results = self.predict(frame)\n",
    "            detections_list = self.get_results(results, frame)\n",
    "\n",
    "            # # SORT Tracking\n",
    "            if len(detections_list) == 0:\n",
    "                detections_list = np.empty((0, 5))\n",
    "\n",
    "            res = sort.update(detections_list)\n",
    "\n",
    "            # boxes_track = res[:,:-1]\n",
    "            # boxes_ids = res[:,-1].astype(int)\n",
    "\n",
    "            # frame = self.draw_bounding_boxes_with_id(frame, boxes_track, boxes_ids)\n",
    "\n",
    "            # end_time = time()\n",
    "            # fps = 1/np.round(end_time - start_time, 2)\n",
    "\n",
    "            # cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "            # cv2.imshow('YOLOv8 Detection', frame)\n",
    " \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "            break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-366-gf7322921 Python-3.9.19 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "custom_YOLOv5s summary: 182 layers, 7254609 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "d:\\projects\\otus\\otus_cv\\hw_final/yolov5\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 360x640 2 tractors\n",
      "Speed: 2.0ms pre-process, 104.9ms inference, 1.0ms NMS per image at shape (1, 3, 384, 640)\n",
      "data_frame:\n",
      "         xmin        ymin        xmax       ymax  confidence  class     name\n",
      "0  319.510437  143.295914  370.080200  181.98262    0.655240      3  tractor\n",
      "1  226.162857  152.792435  286.686249  188.32872    0.529719      3  tractor\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "YOLO_DIR = os.getcwd() + '/yolov5'\n",
    "\n",
    "detector = ObjectDetection(capture_dev=\"./videos/tracktor_competition_360p.mp4\",\n",
    "                           model_path=YOLO_DIR, \n",
    "                           weights_name=YOLO_DIR+\"/best.pt\")\n",
    "detector()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
